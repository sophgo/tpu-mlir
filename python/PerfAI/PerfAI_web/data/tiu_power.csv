Pattern,Function Type,Function Name,Data Type,des_opt_opd0_const,Power
MLP,AR,add,FP32 -> FP32,0.0,0.1201
Attention_QKV,AR,add,FP16 -> FP16,0.0,0.1331
MLP,AR,add_saturate,INT16 -> INT32,0.0,0.1131
Attention_QKV,AR,add_saturate,INT8 -> INT16,0.0,0.1262
MLP,AR,copy,FP32 -> FP32,1.0,0.0403
Attention_QKV,AR,copy,FP16 -> FP16,0.0,0.1132
MLP,AR,data_convert,FP32 -> FP16,0.0,0.0936
MLP,AR,data_convert,FP16 -> FP32,0.0,0.0876
MLP,AR,data_convert,FP32 -> FP32,0.0,0.1019
MLP,AR,data_convert,FP32 -> INT16,0.0,0.087
Attention_QKV,AR,data_convert,FP16 -> FP16,0.0,0.1093
Attention_QKV,AR,data_convert,FP16 -> INT8,0.0,0.0949
MLP,AR,division,FP16 -> FP16,1.0,0.0299
MLP,AR,max,FP32 -> FP32,0.0,0.1186
MLP,AR,max,INT16 -> INT16,0.0,0.1169
Attention_QKV,AR,max,FP16 -> FP16,0.0,0.1187
Attention_QKV,AR,max,INT8 -> INT8,0.0,0.1184
MLP,AR,min,INT16 -> INT16,0.0,0.1175
Attention_QKV,AR,min,FP16 -> FP16,0.0,0.1202
Attention_QKV,AR,min,INT8 -> INT8,0.0,0.1178
MLP,AR,mul,FP32 -> FP32,0.0,0.1633
MLP,AR,mul,FP16 -> FP16,0.0,0.1528
MLP,AR,sub,FP32 -> FP32,0.0,0.1584
MLP,AR,sub,FP16 -> FP16,1.0,0.1051
RMSNorm,CMP,cmp_sel_eq,FP16 -> None,0.0,0.1267
RMSNorm,CONV,conv_normal,FP16 -> FP16,,0.1862
Attention_QKV,CWBC,c_w_transpose,FP16 -> FP16,,0.0489
RMSNorm,CWBC,lane_broadcast,FP16 -> FP16,,0.0634
MLP,CWBC,static_broadcast,FP32 -> FP32,,0.0323
Attention_QKV,CWBC,static_broadcast,FP16 -> FP16,,0.0198
OutputEmbedding,MM2,mm2_nn,FP16 -> FP16,0.0,0.1711
MLP,MM2,mm2_nn,FP16 -> FP32,0.0,0.1732
Attention_QKV,MM2,mm2_tt,FP16 -> FP16,0.0,0.119
Attention_QKV,PorD,average_pooling,FP16 -> FP16,,0.1029
Attention_QKV,PorD,max_pooling,FP16 -> FP16,,0.0282
RMSNorm,SFU,rsqrt(loop=30),FP16 -> FP16,,0.0316
RMSNorm,SFU,rsqrt,FP16 -> FP16,,0.0316
MLP,SFU,tailor_4x(len=10),FP32 -> FP32,,0.0765
Attention_QKV,SFU,tailor_4x(len=7),FP16 -> FP16,,0.0686
MLP,SFU,tailor_4x,FP32 -> FP32,,0.0765
Attention_QKV,SFU,tailor_4x,FP16 -> FP16,,0.0686
MLP,sAR,add,FP32 -> FP32,0.0,0.1201
Attention_QKV,sAR,add,FP16 -> FP16,0.0,0.1331
MLP,sAR,add_saturate,INT16 -> INT32,0.0,0.1131
Attention_QKV,sAR,add_saturate,INT8 -> INT16,0.0,0.1262
MLP,sAR,copy,FP32 -> FP32,1.0,0.0403
Attention_QKV,sAR,copy,FP16 -> FP16,0.0,0.1132
MLP,sAR,data_convert,FP32 -> FP16,0.0,0.0936
MLP,sAR,data_convert,FP16 -> FP32,0.0,0.0876
MLP,sAR,data_convert,FP32 -> FP32,0.0,0.1019
MLP,sAR,data_convert,FP32 -> INT16,0.0,0.087
Attention_QKV,sAR,data_convert,FP16 -> FP16,0.0,0.1093
Attention_QKV,sAR,data_convert,FP16 -> INT8,0.0,0.0949
MLP,sAR,division,FP16 -> FP16,1.0,0.0299
MLP,sAR,max,FP32 -> FP32,0.0,0.1186
MLP,sAR,max,INT16 -> INT16,0.0,0.1169
Attention_QKV,sAR,max,FP16 -> FP16,0.0,0.1187
Attention_QKV,sAR,max,INT8 -> INT8,0.0,0.1184
MLP,sAR,min,INT16 -> INT16,0.0,0.1175
Attention_QKV,sAR,min,FP16 -> FP16,0.0,0.1202
Attention_QKV,sAR,min,INT8 -> INT8,0.0,0.1178
MLP,sAR,mul,FP32 -> FP32,0.0,0.1633
MLP,sAR,mul,FP16 -> FP16,0.0,0.1528
MLP,sAR,sub,FP32 -> FP32,0.0,0.1584
MLP,sAR,sub,FP16 -> FP16,1.0,0.1051
RMSNorm,sCMP,cmp_sel_eq,FP16 -> None,0.0,0.1267
RMSNorm,sCONV,conv_normal,FP16 -> FP16,,0.1862
Attention_QKV,sCWsBC,c_w_transpose,FP16 -> FP16,,0.0489
RMSNorm,sCWsBC,lane_broadcast,FP16 -> FP16,,0.0634
MLP,sCWsBC,static_broadcast,FP32 -> FP32,,0.0323
Attention_QKV,sCWsBC,static_broadcast,FP16 -> FP16,,0.0198
OutputEmbedding,sMM2,mm2_nn,FP16 -> FP16,0.0,0.1711
MLP,sMM2,mm2_nn,FP16 -> FP32,0.0,0.1732
Attention_QKV,sMM2,mm2_tt,FP16 -> FP16,0.0,0.119
Attention_QKV,sPorD,average_pooling,FP16 -> FP16,,0.1029
Attention_QKV,sPorD,max_pooling,FP16 -> FP16,,0.0282
RMSNorm,sSFU,rsqrt(loop=30),FP16 -> FP16,,0.0316
RMSNorm,sSFU,rsqrt,FP16 -> FP16,,0.0316
MLP,sSFU,tailor_4x(len=10),FP32 -> FP32,,0.0765
Attention_QKV,sSFU,tailor_4x(len=7),FP16 -> FP16,,0.0686
MLP,sSFU,tailor_4x,FP32 -> FP32,,0.0765
Attention_QKV,sSFU,tailor_4x,FP16 -> FP16,,0.0686
